# 《机器学习》笔记

标签（空格分隔）： machine_learning

---
#一，绪论

2. 术语
数据集， 样本， 属性或特征， 属性值，属性空间或样本空间，特征向量
维数
训练数据，训练样本，训练集，假设，学习器或模型
预测，标记，样例，标记空间
分类，回归，二分类，多分类
测试，测试样本
聚类，簇
监督学习，无监督学习
泛化：适用新样本
独立同分布：样本空间全部样本服从某一未知分布，每个样本独立取样。

3. 假设空间
归纳 (induction)： 泛化过程
演绎( (deduction)： 特化过程
归纳学习：
广义——从样例中学习
狭义——概念学习，概念形成

学习过程看作在所有假设组成的空间中进行搜索找到与训练集“匹配”的假设。
版本空间：与训练集一致的假设空间

归纳偏好：对某种类型假设的偏好
欧卡姆剃刀(Occam's Razor)

资料：
WEKA
Mitchell,T.(1997).Machine Learning. McGraw Hill, New York, NY.
Witten,et,al.(2011) Data Mining: Practical Machine Learning Tools and Techniques.
会议：
ICML, NIPS, COLT, IJCAI, AAAI
EMCL, AMCL
...

#二， 模型评估与选择

术语：
错误率，精度，误差
训练误差：在训练集上的误差
泛化误差： 在新样本上的误差
过拟合，欠拟合
测试集，测试误差


## 训练/测试划分
- 留出法(hold-out): 直接划分为两个互斥的子集
使用分层采样保持类别比例
单次使用留出法的结果不稳定，往往多次随机划分、重复实验得到的结果取平均值。
- 交叉验证法(cross validation)
先将数据集划分为k个互斥子集，每个子集保持数据分布一致性（分层抽样得到）。然后，每次用k-1个子集的并集作为训练集，剩下的一个作为测试集，共进行k次实验，得到的结果取平均。
这也叫“k折交叉验证(k-fold cross validation)”
k常取10
另外，将数据集划分成k个子集也需要随机划分p次。
例如“10次10折交叉验证”，总共进行100次实验。
- 留一法(Leave-One-Out, LOO)
特殊的交叉验证法： 每个子集就是一个样本。
训练集和原数据集只差一个样本。
计算开销可能很大，过拟合风险
- 自助法 (bootstrapping)
减小训练样本规模变化的影响
以自主采样法(bootstrap sampling)为基础： 每次从数据集中拷贝一个样本，重复若干次。
最后没有出现在训练集中的样本大约占3成，构成了测试集
自助法在数据量小、难以划分训练/测试集时有用。
但是改变了初始数据集的分布，会引入估计偏差。

- 调参 (parameter tuning)
机器学习涉及两类参数： 算法的参数，也称“超参数”，在10以内；模型的参数，数目很多。
对每个参数选定一个范围和变化步长，分别训练模型。
模型评估和选择用的数据集叫验证集(validation set)
模型选择完成后，要要用全部原数据集重新训练模型。

## 性能度量 
(performance measure)

1. 回归任务常用“均方误差(mean square error)”
$$E(f;D) = \frac1 m\sum_{i=1}^m(f(x_i)-y_i)^2$$

2. 错误率、精度
3. 查准率(precision)、查全率(recall)
二分类问题的混淆矩阵 confusion matrix: 
真正例 true positive 
假正例 false negative 
真反例 true negative 
假反例 false negative 
查准率 = TP/(TP + FP)
查全率 = TP/(TP + FN)
- P-R曲线
把学习器的预测结果按照“最可能”是正例到“最不可能”是正例排序，按此顺序逐个把样本作为正例进行预测，每次计算当前的查全率和查准率，就可以画出“P-R曲线”。
若一个学习器的P-R曲线完全被另一个保住，说明后者性能更好。
若两个学习器的P-R曲线交叉，比较与坐标轴包围面积的大小。
或者用“平衡点(Break-Even Point, BEP)”，即两者相等时的取值，该值越大性能越好。
4. 
更常用的是F1度量：两者的调和平均数
（和算术平均、几何平均相比，调和平均更重视较小值）
F1的一般形式——$F_\beta$，加权调和平均
$$\frac 1 {F_\beta} = {1\over 1+\beta^2}(\frac 1 P + \frac {\beta^2} R)$$
$\beta$表示R对P的相对重要性，以1为界。
对于多个二分类混淆矩阵，有两种做法：
-  每个矩阵计算P和R，再取平均值，得到的叫宏值(macro-P/R/F1)。
-   各个矩阵元素取平均，再计算P和R，这叫微值(micro-P/R/F1)。

5. ROC 和 AUC

 








